#!/bin/env python

import subprocess
import csv
from repeater import SamplesPool
from datetime import datetime, timedelta, time
from glob import glob
import click
import os
import shutil
import collections
import itertools
from random import randrange, choice

import operator
import sys

try:
    from reprlib import recursive_repr
except ImportError:
    from backports import recursive_repr


class IndexedOrderedDict(dict):
    """A dictionary that is indexed by insertion order."""

    def __init__(self, *args, **kwds):
        """
        Initialize an ordered dictionary.  The signature is the same as
        regular dictioneries, but keywords arguments are not recommended because
        their insertion order is arbitrary.
        """
        if len(args) > 1:
            raise TypeError('expected at most 1 arguments, got %d' % len(args))

        self._map = []
        self.__update(*args, **kwds)

    def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
        """iod.__setitem__(i, y) <==> iod[i] = y"""
        if key not in self:
            self._map.append(key)
        dict_setitem(self, key, value)

    def __delitem__(self, key, dict_delitem=dict.__delitem__):
        """iod.__delitem__(y) <==> del iod[y]"""
        dict_delitem(self, key)
        self._map.remove(key)

    def __iter__(self):
        """iod.__iter__() <==> iter(iod)"""
        return self._map.__iter__()

    def __reversed__(self):
        """iod.__reversed__() <==> reversed(iod)"""
        return self._map.__reversed__()

    def clear(self):
        """iod.clear() -> None.  Remove all items from iod."""
        self._map[:] = []
        dict.clear(self)

    def popitem(self, last=True):
        """
        iod.popitem() -> (k, v), return and remove a (key, value) pair.
        Pairs are returned LIFO order if last is true or FIFI order if false.
        """
        key = self._map.pop() if last else self._map.pop(0)
        value = dict.pop(self, key)
        return key, value

    def move_to_end(self, key, last=True):
        """
        Move an existing element to the end (or beginning if last==False).

        Raises KeyError if the element does not exist.
        When last=True, acts like a faster version of self[key]=self.pop(key).
        """
        self._map.remove(key)
        if last:
            self._map.append(key)
        else:
            self._map.insert(0, key)

    def __sizeof__(self):
        return sys.getsizeof(self.__dict__) + sys.getsizeof(self._map)

    update = __update = collections.MutableMapping.update
    __ne__ = collections.MutableMapping.__ne__

    def keys(self):
        return IndexedKeysView(self)

    keysview = keys

    def values(self):
        return IndexedValuesView(self)

    valuesview = values

    def items(self):
        return IndexedItemsView(self)

    itemsview = items

    __marker = object()

    def pop(self, key, default=__marker):
        """
        iod.pop(k[,d]) -> v, remove specified key and return the corresponding
        value.  If key is not found, d is returned if given, otherwise KeyError
        is raised.
        """
        if key in self:
            result = self[key]
            del self[key]
            return result
        if default is self.__marker:
            raise KeyError(key)
        return default

    def setdefault(self, key, default=None):
        """
        iod.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in d
        """
        if key in self:
            return self[key]
        self[key] = default
        return default

    @recursive_repr()
    def __repr__(self):
        """iod.__repr__() <==> repr(iod)"""
        if not self:
            return '%s()' % (self.__class__.__name__, )
        return '%s(%r)' % (self.__class__.__name__, list(self.items()))

    def __reduce__(self):
        """Return state information for pickling"""
        inst_dict = vars(self).copy()
        for k in vars(IndexedOrderedDict()):
            inst_dict.pop(k, None)
        return self.__class__, (), inst_dict or None, None, iter(self.items())

    def copy(self):
        """od.copy() -> a shallow copy of iod"""
        return self.__class__(self)

    @classmethod
    def fromkeys(cls, iterable, value=None):
        """
        IOD.fromkeys(S[,v]) -> New indexed ordered dictionary with keys from S.
        If not specified, the value defaults to None.
        """
        self = cls()
        for key in iterable:
            self[key] = value
        return self

    def __eq__(self, other):
        """
        iod.__eq__(y) <==> iod==y.  Comparison to another IOD is
        order-sensitive while comparison to a regular mapping is
        order-insensitive.
        """
        if isinstance(other, collections.OrderedDict) or isinstance(other, IndexedOrderedDict):
            return dict.__eq__(self, other) and all(map(operator.eq, self, other))
        return dict.__eq__(self, other)


class IndexedKeysView(collections.KeysView):

    def __getitem__(self, index):
        return self._mapping._map[index]

    def index(self, x):
        return self._mapping._map.index(x)


class IndexedValuesView(collections.ValuesView):

    def __getitem__(self, index):
        key = self._mapping._map[index]
        return self._mapping[key]


class IndexedItemsView(collections.ItemsView):

    def __getitem__(self, index):
        key = self._mapping._map[index]
        return key, self._mapping[key]

CONTEXTS = IndexedOrderedDict()
CONTEXTS['morning'] = {'exe': 'blender/morning.blend',
                         'start_dt': datetime.strptime("2016-02-01 08:00:00", "%Y-%m-%d %H:%M:%S")}
CONTEXTS['evening'] = {'exe': 'blender/evening.blend',
                         'start_dt': datetime.strptime("2016-02-01 18:00:00", "%Y-%m-%d %H:%M:%S")}

def validate_dt(value):
    try:
        dt = datetime.strptime(value, "%Y-%m-%d %H:%M:%S")
        return dt
    except ValueError:
        raise click.BadParameter("Please enter a valid datetime")

def validate_date(value):
    try:
        dt = datetime.strptime(value, "%Y-%m-%d")
        return dt
    except ValueError:
        raise click.BadParameter("Please enter a valid date")

def random_timestamp(dt, pool_files, time_margin):
    pool_times = [x[x.find(' ')+1:-4] for x in pool_files]
    times = [datetime.strptime(x, "%H:%M:%S") for x in pool_times]
    random_sample = choice(times)
    if time_margin > 0:
        margin = timedelta(seconds=time_margin * 60)
        random_sample = random_date(random_sample - (margin/2), random_sample + (margin/2))
    new_dt = datetime(dt.year, dt.month, dt.day, random_sample.hour, random_sample.minute, random_sample.second)
    return new_dt

def random_date(start, end):
    delta = end - start
    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds
    random_second = randrange(int_delta)
    return start + timedelta(seconds=random_second)

def add_timestamp_field(reader, start_dt):
    if type(start_dt) is str:
        start_dt = datetime.strptime(start_dt, "%Y-%m-%d %H:%M:%S")
    ts = start_dt
    asec = timedelta(seconds=1)
    result = []

    for i in reader:
        row = i + [ts.strftime("%Y-%m-%d %H:%M:%S")]
        result.append(row)
        ts += asec
    return result

def is_weekday(dt):
    if dt.weekday() < 5:
        return True
    else:
        return False


@click.group()
def main():
    """OpenSHS: Open Smart Home Simulator"""
    pass


@main.command()
@click.option('--list-contexts', '-lc', default=False, is_flag=True, help='Lists the available contexts.')
@click.option('--recorded-samples', '-rs', default=False, is_flag=True, help='Shows the status of the recorded contexts samples.')
def status(list_contexts, recorded_samples):
    """Shows the current status of the experiment."""
    if list_contexts:
        click.echo(", ".join([x for x in CONTEXTS.keys()]))

    if recorded_samples:
        for context in CONTEXTS:
            files = glob('temp/*_' + context + '_*.csv')
            weekdays = str(len([f for f in files if f.split('temp/')[1].startswith('weekday')]))
            weekends = str(len([f for f in files if f.split('temp/')[1].startswith('weekend')]))
            click.echo("For context " + click.style(context, bold=True) + ", " + click.style('weekdays', bold=True) + ": " + weekdays + " Samples.")
            click.echo("For context " + click.style(context, bold=True) + ", " + click.style('weekends', bold=True) + ": " + weekends + " Samples.")


@main.command()
@click.option('--context', '-c', type=click.Choice(list(CONTEXTS.keys())), help='Which context to start.')
@click.option('--primusrun', '-p', default=False, is_flag=True, help='Start the context with primus support (Linux Only).')
def start(context, primusrun):
    """Start a context experiment."""
    click.echo('Starting the ' + click.style(context, bold=True) + ' context.')
    start_dt = click.prompt("What's the starting time?",
                            default=CONTEXTS[context]['start_dt'],
                            value_proc=validate_dt)

    CONTEXTS[context]['start_dt'] = start_dt

    weekday_p = is_weekday(start_dt)

    # Write the starting datetime for blender to read
    sf = open('blender/start_time.txt', 'w')
    sf.write(str(int(start_dt.timestamp())))
    sf.close()

    if primusrun:
        subprocess.call(["primusrun", "blender", CONTEXTS[context]['exe']], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    else:
        subprocess.call(["blender", CONTEXTS[context]['exe']], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    os.rename('temp/output.csv', 'temp/' + ('weekday_' if weekday_p else 'weekend_') + context + '_' + datetime.strftime(start_dt, "%Y-%m-%d %H:%M:%S") + '.csv')


@main.command()
@click.option('--days', '-d', type=int, default=30, help='How many days to generate.')
@click.option('--start-date', '-sd', type=validate_date, help='The starting date for the aggregated dataset.')
@click.option('--time-margin', '-tm', type=int, default=0, help='The starting time margin for each replicated sample.')
@click.option('--variable-activities', '-va', default=False, is_flag=True, help='Make the activities duration variable.')
def aggregate(days, start_date, time_margin, variable_activities):
    """Aggregate the datasets."""

    files = glob('temp/*.csv')

    aday = timedelta(days=1)
    dt = start_date

    # The header row
    with open(files[0], 'r') as headfile:
        csv_reader = csv.reader(headfile)
        header = next(csv_reader)
    header.append('timestamp')

    d_rows = []
    with open('datasets/dataset.csv', 'w') as outf:
        csv_writer = csv.writer(outf)
        csv_writer.writerow(header)

        for _ in range(days):
            if is_weekday(dt):
                for context in CONTEXTS:
                    pool_files = glob('temp/weekday_' + context + '*.csv')
                    pool = SamplesPool(pool_files, variable_activities)
                    rep_rows = pool.generate_sample(header=False)
                    d_rows += add_timestamp_field(rep_rows, random_timestamp(dt, pool_files, time_margin))
            else:
                for context in CONTEXTS:
                    pool_files = glob('temp/weekend_' + context + '*.csv')
                    pool = SamplesPool(pool_files, variable_activities)
                    rep_rows = pool.generate_sample(header=False)
                    d_rows += add_timestamp_field(rep_rows, random_timestamp(dt, pool_files, time_margin))
            dt += aday

        csv_writer.writerows(d_rows)


if __name__ == '__main__':
    main()
